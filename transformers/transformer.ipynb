{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from importlib import reload\n",
    "import transformer\n",
    "reload(transformer)\n",
    "from transformer import GPT, GPTConfig, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small GPT model\n",
    "config = GPTConfig(\n",
    "    context_size=256,\n",
    "    vocab_size=50257,\n",
    "    n_layer=6,\n",
    "    n_head=6,\n",
    "    n_embd=384\n",
    ")\n",
    "model = GPT(config)\n",
    "\n",
    "# Print model info\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {n_params / 1e6:.2f}M\")\n",
    "print(f\"Config: {config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass with random tokens\n",
    "tokens = torch.randint(0, 50257, (4, 128))  # Batch of 4, seq len 128\n",
    "logits, loss = model(tokens)  # logits: (4, 128, 50257)\n",
    "print(f\"Input shape: {tokens.shape}\")\n",
    "print(f\"Output logits shape: {logits.shape}\")\n",
    "print(f\"Loss (no targets): {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass with targets (for training)\n",
    "targets = torch.randint(0, 50257, (4, 128))\n",
    "logits, loss = model(tokens, targets)\n",
    "print(f\"Loss (with targets): {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text generation (with random tokens as prompt)\n",
    "prompt = torch.randint(0, 50257, (1, 10))  # Starting tokens\n",
    "print(f\"Prompt shape: {prompt.shape}\")\n",
    "\n",
    "generated = model.generate(prompt, max_new_tokens=50, temperature=0.8, top_k=40)\n",
    "print(f\"Generated shape: {generated.shape}\")\n",
    "print(f\"Generated tokens: {generated[0].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple training example with a dummy dataloader\n",
    "class DummyDataLoader:\n",
    "    \"\"\"Simple dataloader that generates random token sequences.\"\"\"\n",
    "    def __init__(self, vocab_size, seq_len, batch_size):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def next_batch(self):\n",
    "        # Generate random input and target sequences\n",
    "        # Target is input shifted by 1 (next token prediction)\n",
    "        data = torch.randint(0, self.vocab_size, (self.batch_size, self.seq_len + 1))\n",
    "        x = data[:, :-1]\n",
    "        y = data[:, 1:]\n",
    "        return x, y\n",
    "\n",
    "# Create dataloader\n",
    "dataloader = DummyDataLoader(vocab_size=50257, seq_len=128, batch_size=4)\n",
    "\n",
    "# Create fresh model and optimizer\n",
    "model = GPT(config)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "\n",
    "# Train for a few steps\n",
    "model = train(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    n_steps=20,\n",
    "    optimizer=optimizer,\n",
    "    device='cpu',\n",
    "    log_interval=5\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
